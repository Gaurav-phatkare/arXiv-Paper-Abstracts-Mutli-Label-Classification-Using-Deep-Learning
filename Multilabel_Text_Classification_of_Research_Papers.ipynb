{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOe5HK6XeDScLWLvCOTAfhN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gaurav-phatkare/arXiv-Paper-Abstracts-Mutli-Label-Classification-Using-Deep-Learning/blob/main/Multilabel_Text_Classification_of_Research_Papers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U04hmFgUMhML",
        "outputId": "937594d8-9c7c-4c8e-e150-0e528169da43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Aug  4 05:49:30 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "tpIVgr1oNBTl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5ehdK2eNK7l",
        "outputId": "b12034d6-8b78-4b5c-91f8-f1ea45399b04"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.16)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "ZawQ5lGSNNba"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "n-lxN8buNiZh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "0cbVVLAfNn1C"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d spsayakpaul/arxiv-paper-abstracts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoGBXDUvNrkL",
        "outputId": "2d961b9e-01d6-4478-cd26-ef3222d832e9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading arxiv-paper-abstracts.zip to /content\n",
            " 99% 44.0M/44.6M [00:03<00:00, 16.3MB/s]\n",
            "100% 44.6M/44.6M [00:03<00:00, 13.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/arxiv-paper-abstracts.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0g58nFCN2cF",
        "outputId": "0e26da13-e090-4e56-9d5d-f544c59ba884"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/arxiv-paper-abstracts.zip\n",
            "  inflating: arxiv_data.csv          \n",
            "  inflating: arxiv_data_210930-054931.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/arxiv_data.csv\")"
      ],
      "metadata": {
        "id": "-ObPstnCN70d"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEXAwYLRO4Cx",
        "outputId": "16d1da01-db1e-488f-e683-0124cfd599ac"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51774, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Gg0NdSfePZTZ",
        "outputId": "f1754e7c-6cb2-469e-f684-17a1b5127c6c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              titles  \\\n",
              "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
              "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
              "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
              "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
              "4  Background-Foreground Segmentation for Interio...   \n",
              "\n",
              "                                           summaries  \\\n",
              "0  Stereo matching is one of the widely used tech...   \n",
              "1  The recent advancements in artificial intellig...   \n",
              "2  In this paper, we proposed a novel mutual cons...   \n",
              "3  Consistency training has proven to be an advan...   \n",
              "4  To ensure safety in automated driving, the cor...   \n",
              "\n",
              "                         terms  \n",
              "0           ['cs.CV', 'cs.LG']  \n",
              "1  ['cs.CV', 'cs.AI', 'cs.LG']  \n",
              "2           ['cs.CV', 'cs.AI']  \n",
              "3                    ['cs.CV']  \n",
              "4           ['cs.CV', 'cs.LG']  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-2293ee9d-10fd-4862-a867-5f837a0e9d52\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "      <th>summaries</th>\n",
              "      <th>terms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
              "      <td>Stereo matching is one of the widely used tech...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
              "      <td>The recent advancements in artificial intellig...</td>\n",
              "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
              "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
              "      <td>['cs.CV', 'cs.AI']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
              "      <td>Consistency training has proven to be an advan...</td>\n",
              "      <td>['cs.CV']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Background-Foreground Segmentation for Interio...</td>\n",
              "      <td>To ensure safety in automated driving, the cor...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2293ee9d-10fd-4862-a867-5f837a0e9d52')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-b116379f-71eb-4868-801f-7156634161ee\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b116379f-71eb-4868-801f-7156634161ee')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-b116379f-71eb-4868-801f-7156634161ee button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2293ee9d-10fd-4862-a867-5f837a0e9d52 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2293ee9d-10fd-4862-a867-5f837a0e9d52');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[4].summaries,df.iloc[4].terms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8L7a-CAzPahG",
        "outputId": "e3a7167a-9cd7-4339-d206-6f1f77334c79"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('To ensure safety in automated driving, the correct perception of the\\nsituation inside the car is as important as its environment. Thus, seat\\noccupancy detection and classification of detected instances play an important\\nrole in interior sensing. By the knowledge of the seat occupancy status, it is\\npossible to, e.g., automate the airbag deployment control. Furthermore, the\\npresence of a driver, which is necessary for partially automated driving cars\\nat the automation levels two to four can be verified. In this work, we compare\\ndifferent statistical methods from the field of image segmentation to approach\\nthe problem of background-foreground segmentation in camera based interior\\nsensing. In the recent years, several methods based on different techniques\\nhave been developed and applied to images or videos from different\\napplications. The peculiarity of the given scenarios of interior sensing is,\\nthat the foreground instances and the background both contain static as well as\\ndynamic elements. In data considered in this work, even the camera position is\\nnot completely fixed. We review and benchmark three different methods ranging,\\ni.e., Gaussian Mixture Models (GMM), Morphological Snakes and a deep neural\\nnetwork, namely a Mask R-CNN. In particular, the limitations of the classical\\nmethods, GMM and Morphological Snakes, for interior sensing are shown.\\nFurthermore, it turns, that it is possible to overcome these limitations by\\ndeep learning, e.g.\\\\ using a Mask R-CNN. Although only a small amount of ground\\ntruth data was available for training, we enabled the Mask R-CNN to produce\\nhigh quality background-foreground masks via transfer learning. Moreover, we\\ndemonstrate that certain augmentation as well as pre- and post-processing\\nmethods further enhance the performance of the investigated methods.',\n",
              " \"['cs.CV', 'cs.LG']\")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['titles'].duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlYZohgNP5x1",
        "outputId": "2948909a-f4ff-45f7-e517-70c1f41579a7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12802"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace = True)"
      ],
      "metadata": {
        "id": "jgjgrhrMSNiS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HssEhOASYbnn",
        "outputId": "bb65c25b-e8a4-483e-b8d7-b5846bb09ad7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38991, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def Text_cleaning(text):\n",
        "  text = re.sub(r\"\\n\" , \" \", text)\n",
        "\n",
        "  text = re.sub(r\"\\s+\" , \" \", text)\n",
        "\n",
        "  text = text.lower()\n",
        "  text = text.replace('\\n',\" \")\n",
        "\n",
        "  return text\n",
        "\n"
      ],
      "metadata": {
        "id": "6GOx_bbzYdkr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Text_cleaning(df.iloc[4].summaries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "9A3J3KFLZlne",
        "outputId": "2cfbfd33-8f6f-4b3f-d8d0-a0ac7269bb9e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'to ensure safety in automated driving, the correct perception of the situation inside the car is as important as its environment. thus, seat occupancy detection and classification of detected instances play an important role in interior sensing. by the knowledge of the seat occupancy status, it is possible to, e.g., automate the airbag deployment control. furthermore, the presence of a driver, which is necessary for partially automated driving cars at the automation levels two to four can be verified. in this work, we compare different statistical methods from the field of image segmentation to approach the problem of background-foreground segmentation in camera based interior sensing. in the recent years, several methods based on different techniques have been developed and applied to images or videos from different applications. the peculiarity of the given scenarios of interior sensing is, that the foreground instances and the background both contain static as well as dynamic elements. in data considered in this work, even the camera position is not completely fixed. we review and benchmark three different methods ranging, i.e., gaussian mixture models (gmm), morphological snakes and a deep neural network, namely a mask r-cnn. in particular, the limitations of the classical methods, gmm and morphological snakes, for interior sensing are shown. furthermore, it turns, that it is possible to overcome these limitations by deep learning, e.g.\\\\ using a mask r-cnn. although only a small amount of ground truth data was available for training, we enabled the mask r-cnn to produce high quality background-foreground masks via transfer learning. moreover, we demonstrate that certain augmentation as well as pre- and post-processing methods further enhance the performance of the investigated methods.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['cleaned_summary'] = df['summaries'].apply(Text_cleaning)"
      ],
      "metadata": {
        "id": "oAZr8RxRZqSV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hgtig_YEaE6_",
        "outputId": "e0a8f01a-4aed-4253-b844-e051f73749b2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              titles  \\\n",
              "0  Survey on Semantic Stereo Matching / Semantic ...   \n",
              "1  FUTURE-AI: Guiding Principles and Consensus Re...   \n",
              "2  Enforcing Mutual Consistency of Hard Regions f...   \n",
              "3  Parameter Decoupling Strategy for Semi-supervi...   \n",
              "4  Background-Foreground Segmentation for Interio...   \n",
              "\n",
              "                                           summaries  \\\n",
              "0  Stereo matching is one of the widely used tech...   \n",
              "1  The recent advancements in artificial intellig...   \n",
              "2  In this paper, we proposed a novel mutual cons...   \n",
              "3  Consistency training has proven to be an advan...   \n",
              "4  To ensure safety in automated driving, the cor...   \n",
              "\n",
              "                         terms  \\\n",
              "0           ['cs.CV', 'cs.LG']   \n",
              "1  ['cs.CV', 'cs.AI', 'cs.LG']   \n",
              "2           ['cs.CV', 'cs.AI']   \n",
              "3                    ['cs.CV']   \n",
              "4           ['cs.CV', 'cs.LG']   \n",
              "\n",
              "                                     cleaned_summary  \n",
              "0  stereo matching is one of the widely used tech...  \n",
              "1  the recent advancements in artificial intellig...  \n",
              "2  in this paper, we proposed a novel mutual cons...  \n",
              "3  consistency training has proven to be an advan...  \n",
              "4  to ensure safety in automated driving, the cor...  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-dc76a7f8-062c-4c7c-ab22-7c282770cccd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "      <th>summaries</th>\n",
              "      <th>terms</th>\n",
              "      <th>cleaned_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Survey on Semantic Stereo Matching / Semantic ...</td>\n",
              "      <td>Stereo matching is one of the widely used tech...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "      <td>stereo matching is one of the widely used tech...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
              "      <td>The recent advancements in artificial intellig...</td>\n",
              "      <td>['cs.CV', 'cs.AI', 'cs.LG']</td>\n",
              "      <td>the recent advancements in artificial intellig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Enforcing Mutual Consistency of Hard Regions f...</td>\n",
              "      <td>In this paper, we proposed a novel mutual cons...</td>\n",
              "      <td>['cs.CV', 'cs.AI']</td>\n",
              "      <td>in this paper, we proposed a novel mutual cons...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Parameter Decoupling Strategy for Semi-supervi...</td>\n",
              "      <td>Consistency training has proven to be an advan...</td>\n",
              "      <td>['cs.CV']</td>\n",
              "      <td>consistency training has proven to be an advan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Background-Foreground Segmentation for Interio...</td>\n",
              "      <td>To ensure safety in automated driving, the cor...</td>\n",
              "      <td>['cs.CV', 'cs.LG']</td>\n",
              "      <td>to ensure safety in automated driving, the cor...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc76a7f8-062c-4c7c-ab22-7c282770cccd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-55c71d39-1c4d-466b-ad68-3855083b54c7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-55c71d39-1c4d-466b-ad68-3855083b54c7')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-55c71d39-1c4d-466b-ad68-3855083b54c7 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc76a7f8-062c-4c7c-ab22-7c282770cccd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc76a7f8-062c-4c7c-ab22-7c282770cccd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no9r3nE4aOF4",
        "outputId": "a3796a3d-69c4-4797-9c36-78fc72d7ee86"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 38991 entries, 0 to 51772\n",
            "Data columns (total 4 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   titles           38991 non-null  object\n",
            " 1   summaries        38991 non-null  object\n",
            " 2   terms            38991 non-null  object\n",
            " 3   cleaned_summary  38991 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 1.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(df['terms'].value_counts() == 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qPyeOa3xH4K",
        "outputId": "997fb6f8-3295-4b43-8c08-601a16c12b5b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2321"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = df.groupby('terms').filter(lambda x:len(x) > 1)\n",
        "new_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV_l6KZLxHyd",
        "outputId": "68e26750-ee2f-4376-edb5-51167a503325"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36670, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7lwRZFfxHsD",
        "outputId": "9c9b15be-470e-495c-88fa-723591a59be3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VVsvivq4xHkv"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## convert the string labels to lists of strings"
      ],
      "metadata": {
        "id": "W2p658uzbQj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "new_df['terms'] = new_df['terms'].apply(lambda x: ast.literal_eval(x))"
      ],
      "metadata": {
        "id": "p1r7bD7YbgPU"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.terms.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ch0_7p8cpo3",
        "outputId": "503b484e-1fb0-45ca-8fb0-115ef7c5c52e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[cs.CV]                                               12753\n",
              "[cs.LG, stat.ML]                                       4076\n",
              "[cs.LG]                                                2047\n",
              "[cs.CV, cs.LG]                                         1488\n",
              "[cs.LG, cs.AI]                                         1207\n",
              "                                                      ...  \n",
              "[cs.CV, cs.LG, eess.IV, eess.SP, stat.ML]                 2\n",
              "[cs.LG, cs.CL, cs.CV, cs.NE, stat.ML]                     2\n",
              "[stat.ML, cs.IT, cs.LG, math.IT, math.ST, stat.TH]        2\n",
              "[cs.CV, cs.CL, cs.LG, eess.AS, eess.IV]                   2\n",
              "[cs.LG, G.3]                                              2\n",
              "Name: terms, Length: 836, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spliting into train test split"
      ],
      "metadata": {
        "id": "GfHLShvBdNde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# train_df, test_df_0 = train_test_split(\n",
        "#     new_df,\n",
        "#     test_size = 0.1,\n",
        "#     stratify = new_df['terms'].values\n",
        "# )"
      ],
      "metadata": {
        "id": "zI3iXIBCdWvG"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_df.shape, test_df_0.shape"
      ],
      "metadata": {
        "id": "6i_mS6pyy3dX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # spliting test data further into test and validation\n",
        "\n",
        "# test_df, val_df = train_test_split(\n",
        "#     test_df_0,\n",
        "#     train_size = 0.5,\n",
        "#     stratify = new_df['terms'].values\n",
        "# )"
      ],
      "metadata": {
        "id": "sGY0dhHMgW7d"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_dataset(data, train_ratio=0.8, test_ratio=0.1, val_ratio=0.1, random_seed=42):\n",
        "\n",
        "    train_data, temp_data = train_test_split(data, train_size=train_ratio, random_state=random_seed)\n",
        "    test_data, val_data = train_test_split(temp_data, train_size=test_ratio / (test_ratio + val_ratio),\n",
        "                                           random_state=random_seed)\n",
        "\n",
        "    return train_data, test_data, val_data\n",
        "\n",
        "\n",
        "train_data, test_data, val_data = split_dataset(new_df, train_ratio=0.8, test_ratio=0.1, val_ratio=0.1)\n"
      ],
      "metadata": {
        "id": "AvYvYGr3yv1h"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data),len(test_data),len(val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlyRsS_d0kjc",
        "outputId": "326b497f-ac14-40db-c6b6-5c681b7ee6b1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29336, 3667, 3667)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-label Binarization"
      ],
      "metadata": {
        "id": "BR1npxc-0puN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "terms = tf.ragged.constant(train_data['terms'].values)\n",
        "lookup = tf.keras.layers.StringLookup(output_mode = 'multi_hot')\n",
        "lookup.adapt(terms)\n",
        "vocab = lookup.get_vocabulary()"
      ],
      "metadata": {
        "id": "4fJx11Wy6j5t"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hisc_u06v2Q",
        "outputId": "078c3e7b-2433-4012-8777-f50999dc7b98"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[UNK]',\n",
              " 'cs.CV',\n",
              " 'cs.LG',\n",
              " 'stat.ML',\n",
              " 'cs.AI',\n",
              " 'eess.IV',\n",
              " 'cs.RO',\n",
              " 'cs.CL',\n",
              " 'cs.NE',\n",
              " 'cs.CR',\n",
              " 'math.OC',\n",
              " 'eess.SP',\n",
              " 'cs.GR',\n",
              " 'cs.SI',\n",
              " 'cs.MM',\n",
              " 'cs.SY',\n",
              " 'cs.IR',\n",
              " 'eess.SY',\n",
              " 'cs.MA',\n",
              " 'cs.HC',\n",
              " 'cs.DC',\n",
              " 'math.IT',\n",
              " 'cs.IT',\n",
              " 'cs.CY',\n",
              " 'stat.AP',\n",
              " 'stat.TH',\n",
              " 'math.ST',\n",
              " 'stat.ME',\n",
              " 'eess.AS',\n",
              " 'cs.SD',\n",
              " 'q-bio.QM',\n",
              " 'cs.DS',\n",
              " 'q-bio.NC',\n",
              " 'cs.NI',\n",
              " 'cs.SE',\n",
              " 'I.2.6',\n",
              " 'stat.CO',\n",
              " 'cs.CG',\n",
              " 'cs.GT',\n",
              " 'math.NA',\n",
              " 'physics.chem-ph',\n",
              " 'cs.NA',\n",
              " 'cs.DB',\n",
              " 'cs.LO',\n",
              " 'cs.PL',\n",
              " '68T45',\n",
              " 'q-bio.BM',\n",
              " 'physics.comp-ph',\n",
              " 'math.PR',\n",
              " 'cs.AR',\n",
              " 'cond-mat.dis-nn',\n",
              " 'math.DS',\n",
              " 'I.2.10',\n",
              " 'cs.CE',\n",
              " 'physics.data-an',\n",
              " 'quant-ph',\n",
              " '68T05',\n",
              " 'q-fin.ST',\n",
              " 'cond-mat.stat-mech',\n",
              " 'cs.DM',\n",
              " 'physics.soc-ph',\n",
              " 'cs.CC',\n",
              " 'astro-ph.IM',\n",
              " 'I.4.6',\n",
              " 'q-bio.GN',\n",
              " 'econ.EM',\n",
              " 'physics.med-ph',\n",
              " 'cs.PF',\n",
              " 'I.4.8',\n",
              " 'q-fin.TR',\n",
              " 'physics.ao-ph',\n",
              " '68U10',\n",
              " 'math.AT',\n",
              " 'I.2',\n",
              " 'hep-ex',\n",
              " 'cs.FL',\n",
              " 'cond-mat.mtrl-sci',\n",
              " 'I.5.4',\n",
              " 'I.4',\n",
              " 'physics.optics',\n",
              " 'physics.geo-ph',\n",
              " 'math.AP',\n",
              " 'I.4; I.5',\n",
              " 'I.2.6; I.2.8',\n",
              " '68T01',\n",
              " '65D19',\n",
              " 'q-fin.CP',\n",
              " 'physics.flu-dyn',\n",
              " 'nlin.CD',\n",
              " '68T10',\n",
              " 'math.CO',\n",
              " 'cs.SC',\n",
              " 'cs.MS',\n",
              " 'I.4.9',\n",
              " 'I.2.8',\n",
              " 'I.2.6; I.5.1',\n",
              " 'I.2.0; I.2.6',\n",
              " '68U01',\n",
              " '68T30',\n",
              " '68T07',\n",
              " '68',\n",
              " 'q-fin.GN',\n",
              " 'q-fin.EC',\n",
              " 'econ.GN',\n",
              " 'cs.ET',\n",
              " 'K.3.2',\n",
              " 'I.4.5',\n",
              " 'I.2; I.5',\n",
              " 'I.2.10; I.4.8',\n",
              " 'q-fin.RM',\n",
              " 'q-bio.TO',\n",
              " 'q-bio.OT',\n",
              " 'q-bio.MN',\n",
              " 'physics.bio-ph',\n",
              " 'math.FA',\n",
              " 'cond-mat.soft',\n",
              " 'I.4.9; I.5.4',\n",
              " 'I.4.6; I.4.8',\n",
              " 'I.4.4',\n",
              " 'I.4.3',\n",
              " 'I.2; I.4; I.5',\n",
              " 'I.2; I.2.6; I.2.7',\n",
              " 'I.2.7',\n",
              " 'I.2.6; I.5.4',\n",
              " 'I.2.6; I.2.9',\n",
              " 'I.2.6; I.2.7; H.3.1; H.3.3',\n",
              " 'I.2.6; I.2.7',\n",
              " 'I.2.6, I.5.4',\n",
              " 'I.2.1; J.3',\n",
              " 'I.2.10; I.4; I.5',\n",
              " 'I.2.10; I.4.8; I.5.4',\n",
              " 'I.2.1',\n",
              " 'H.3.1; I.2.6; I.2.7',\n",
              " 'H.3.1; H.3.3; I.2.6; I.2.7',\n",
              " 'G.3',\n",
              " 'F.2.2; I.2.7',\n",
              " 'E.5; E.4; E.2; H.1.1; F.1.1; F.1.3',\n",
              " '68T99',\n",
              " '68Q32',\n",
              " '14J60 (Primary) 14F05, 14J26 (Secondary)',\n",
              " 'q-fin.PM',\n",
              " 'nlin.AO',\n",
              " 'hep-ph',\n",
              " 'I.4.0',\n",
              " 'I.2; J.2',\n",
              " 'I.2.6; I.2.10',\n",
              " 'I.2.10; I.5.1; I.4.8',\n",
              " 'I.2.10; I.2.6',\n",
              " '68Txx',\n",
              " '62H99',\n",
              " '62H30']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def invert_multi_hot(encoded_labels):\n",
        "  hot_indices = np.argwhere(encoded_labels == 1.0)[...,0]\n",
        "  return np.take(vocab, hot_indices)"
      ],
      "metadata": {
        "id": "NXVYqwiU6xkt"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "ind = np.argwhere([1,0,0,1,0])[...,0]\n",
        "np.take(['a','b','c','d','e'],ind)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iMOx3hR945y",
        "outputId": "393242a7-5239-4627-92bf-639bea7e8e5a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['a', 'd'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Try multi hot with some sample**"
      ],
      "metadata": {
        "id": "SW0Hu7dOHp-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_label = train_data['terms'].iloc[0]\n",
        "sample_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew4Dxy5c96Gd",
        "outputId": "64fffb3b-283f-483c-c189-29ba4f920f48"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cs.CV', 'cs.LG', 'eess.IV']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_binarized = lookup(sample_label)\n",
        "label_binarized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyHrOgiYG5ko",
        "outputId": "172c50ab-ea78-40f6-9e5f-dd8de356c407"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(151,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Invert binarized labels to sample labels**"
      ],
      "metadata": {
        "id": "5b8oJ4ESIwEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "invert_multi_hot(label_binarized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69r8mhvWH-x1",
        "outputId": "a66edc3d-ddf1-4c35-d555-945ac05c424f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['cs.CV', 'cs.LG', 'eess.IV'], dtype='<U40')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def length(x):\n",
        "  x = x.split(\" \")\n",
        "  return len(x)"
      ],
      "metadata": {
        "id": "61cYZcibKf6M"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['cleaned_summary'].apply(length).describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDDmAFHWIU0h",
        "outputId": "15d4e5fa-b433-415b-ec1c-abb6454a0c9a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    29336.000000\n",
              "mean       171.597491\n",
              "std         45.364715\n",
              "min          5.000000\n",
              "25%        140.000000\n",
              "50%        169.000000\n",
              "75%        201.000000\n",
              "max        498.000000\n",
              "Name: cleaned_summary, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing dataset"
      ],
      "metadata": {
        "id": "4MuyjLHMKsdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 160\n",
        "batch_size = 32\n",
        "padding_token = '<pad>'\n",
        "auto = tf.data.AUTOTUNE\n",
        "\n",
        "\n",
        "def make_dataset(dataframe, is_train=True):\n",
        "  labels = tf.ragged.constant(dataframe['terms'].values)\n",
        "  label_binarized = lookup(labels).numpy()\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(\n",
        "      (dataframe['cleaned_summary'].values, label_binarized)\n",
        "  )\n",
        "  dataset = dataset.shuffle(batch_size * 10) if is_train else dataset\n",
        "  return dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "87Eb8bqeLS_U"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = make_dataset(train_data,is_train=True)\n",
        "val_dataset = make_dataset(val_data,is_train=False)\n",
        "test_dataset = make_dataset(test_data,is_train=False)"
      ],
      "metadata": {
        "id": "DAhW6gmqNNcW"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_batch, label_batch = next(iter(train_dataset))\n",
        "\n",
        "for i, text in enumerate(text_batch[:5]):\n",
        "  label = label_batch[i].numpy()[None,...]\n",
        "  print(f'Abstract:{text}')\n",
        "  print(f\"labels: {invert_multi_hot(label[0])}\")\n",
        "  print(\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9s46KowNZQE",
        "outputId": "66086df6-7b03-4b59-91e2-425037fb55fa"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abstract:b'despite the substantial progress of active learning for image recognition, there still lacks an instance-level active learning method specified for object detection. in this paper, we propose multiple instance active object detection (mi-aod), to select the most informative images for detector training by observing instance-level uncertainty. mi-aod defines an instance uncertainty learning module, which leverages the discrepancy of two adversarial instance classifiers trained on the labeled set to predict instance uncertainty of the unlabeled set. mi-aod treats unlabeled images as instance bags and feature anchors in images as instances, and estimates the image uncertainty by re-weighting instances in a multiple instance learning (mil) fashion. iterative instance uncertainty learning and re-weighting facilitate suppressing noisy instances, toward bridging the gap between instance uncertainty and image-level uncertainty. experiments validate that mi-aod sets a solid baseline for instance-level active learning. on commonly used object detection datasets, mi-aod outperforms state-of-the-art methods with significant margins, particularly when the labeled sets are small. code is available at https://github.com/yuantn/mi-aod.'\n",
            "labels: ['cs.CV' 'cs.LG' 'cs.AI']\n",
            " \n",
            "Abstract:b\"the signature transform is a 'universal nonlinearity' on the space of continuous vector-valued paths, and has received attention for use in machine learning on time series. however, real-world temporal data is typically observed at discrete points in time, and must first be transformed into a continuous path before signature techniques can be applied. we make this step explicit by characterising it as an imputation problem, and empirically assess the impact of various imputation strategies when applying signature-based neural nets to irregular time series data. for one of these strategies, gaussian process (gp) adapters, we propose an extension~(gp-pom) that makes uncertainty information directly available to the subsequent classifier while at the same time preventing costly monte-carlo (mc) sampling. in our experiments, we find that the choice of imputation drastically affects shallow signature models, whereas deeper architectures are more robust. next, we observe that uncertainty-aware predictions (based on gp-pom or indicator imputations) are beneficial for predictive performance, even compared to the uncertainty-aware training of conventional gp adapters. in conclusion, we have demonstrated that the path construction is indeed crucial for signature models and that our proposed strategy leads to competitive performance in general, while improving robustness of signature models in particular.\"\n",
            "labels: ['cs.LG' 'stat.ML']\n",
            " \n",
            "Abstract:b'the covid-19 pandemic has drastically changed accepted norms globally. within the past year, masks have been used as a public health response to limit the spread of the virus. this sudden change has rendered many face recognition based access control, authentication and surveillance systems ineffective. official documents such as passports, driving license and national identity cards are enrolled with fully uncovered face images. however, in the current global situation, face matching systems should be able to match these reference images with masked face images. as an example, in an airport or security checkpoint it is safer to match the unmasked image of the identifying document to the masked person rather than asking them to remove the mask. we find that current facial recognition techniques are not robust to this form of occlusion. to address this unique requirement presented due to the current circumstance, we propose a set of re-purposed datasets and a benchmark for researchers to use. we also propose a contrastive visual representation learning based pre-training workflow which is specialized to masked vs unmasked face matching. we ensure that our method learns robust features to differentiate people across varying data collection scenarios. we achieve this by training over many different datasets and validating our result by testing on various holdout datasets. the specialized weights trained by our method outperform standard face recognition features for masked to unmasked face matching. we believe the provided synthetic mask generating code, our novel training approach and the trained weights from the masked face models will help in adopting existing face recognition systems to operate in the current global environment. we open-source all contributions for broader use by the research community.'\n",
            "labels: ['cs.CV' 'eess.IV']\n",
            " \n",
            "Abstract:b\"process monitoring involves tracking a system's behaviors, evaluating the current state of the system, and discovering interesting events that require immediate actions. in this paper, we consider monitoring temporal system state sequences to help detect the changes of dynamic systems, check the divergence of the system development, and evaluate the significance of the deviation. we begin with discussions of data reduction, symbolic data representation, and the anomaly detection in temporal discrete sequences. time-series representation methods are also discussed and used in this paper to discretize raw data into sequences of system states. markov chains and stationary state distributions are continuously generated from temporal sequences to represent snapshots of the system dynamics in different time frames. we use generalized jensen-shannon divergence as the measure to monitor changes of the stationary symbol probability distributions and evaluate the significance of system deviations. we prove that the proposed approach is able to detect deviations of the systems we monitor and assess the deviation significance in probabilistic manner.\"\n",
            "labels: ['cs.LG' 'stat.ML']\n",
            " \n",
            "Abstract:b'current top performing object detectors employ detection proposals to guide the search for objects, thereby avoiding exhaustive sliding window search across images. despite the popularity and widespread use of detection proposals, it is unclear which trade-offs are made when using them during object detection. we provide an in-depth analysis of twelve proposal methods along with four baselines regarding proposal repeatability, ground truth annotation recall on pascal, imagenet, and ms coco, and their impact on dpm, r-cnn, and fast r-cnn detection performance. our analysis shows that for object detection improving proposal localisation accuracy is as important as improving recall. we introduce a novel metric, the average recall (ar), which rewards both high recall and good localisation and correlates surprisingly well with detection performance. our findings show common strengths and weaknesses of existing methods, and provide insights and metrics for selecting and tuning proposal methods.'\n",
            "labels: ['cs.CV']\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jY-Sza6uN3El"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}